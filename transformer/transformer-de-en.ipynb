{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cbe4273",
   "metadata": {
    "_cell_guid": "a504558a-7d18-44ee-9881-a3225a0db122",
    "_uuid": "6bf3ca93-0e5e-4223-ae54-c0d67be2f68e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T00:20:12.256177Z",
     "iopub.status.busy": "2025-01-31T00:20:12.255877Z",
     "iopub.status.idle": "2025-01-31T00:20:24.244042Z",
     "shell.execute_reply": "2025-01-31T00:20:24.243332Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 11.997055,
     "end_time": "2025-01-31T00:20:24.245603",
     "exception": false,
     "start_time": "2025-01-31T00:20:12.248548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3e07b6",
   "metadata": {
    "_cell_guid": "b76fed09-fa37-40a5-89bb-623f2daf6e3b",
    "_uuid": "91bec00a-e564-417b-90cc-5ebb93d5f593",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004583,
     "end_time": "2025-01-31T00:20:24.255627",
     "exception": false,
     "start_time": "2025-01-31T00:20:24.251044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16e83d40",
   "metadata": {
    "_cell_guid": "8a8d1b10-764b-4349-a905-d0f0e66c75b6",
    "_uuid": "c0842070-4a61-47b9-b145-42389596a4c2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T00:20:24.265911Z",
     "iopub.status.busy": "2025-01-31T00:20:24.265460Z",
     "iopub.status.idle": "2025-01-31T00:20:24.757567Z",
     "shell.execute_reply": "2025-01-31T00:20:24.756415Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.498721,
     "end_time": "2025-01-31T00:20:24.758996",
     "exception": false,
     "start_time": "2025-01-31T00:20:24.260275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>German</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hallo!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Grüß Gott!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Lauf!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run</td>\n",
       "      <td>Lauf!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Potzdonner!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English       German\n",
       "0      Hi       Hallo!\n",
       "1      Hi   Grüß Gott!\n",
       "2    Run!        Lauf!\n",
       "3     Run        Lauf!\n",
       "4    Wow!  Potzdonner!"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/english-to-german/english_to_german.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8cc8254",
   "metadata": {
    "_cell_guid": "8fb7243a-d6fd-44ab-b175-1aa33aecc35b",
    "_uuid": "740cd758-a46e-4960-be7b-067bb15d41a6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T00:20:24.769862Z",
     "iopub.status.busy": "2025-01-31T00:20:24.769639Z",
     "iopub.status.idle": "2025-01-31T00:20:24.862171Z",
     "shell.execute_reply": "2025-01-31T00:20:24.861084Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.099351,
     "end_time": "2025-01-31T00:20:24.863585",
     "exception": false,
     "start_time": "2025-01-31T00:20:24.764234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   source  \\\n",
      "113497              Ich möchte noch ein bisschen schlafen   \n",
      "22466                                      Es wird kälter   \n",
      "143788  Niemand wusste, dass Tom hier nicht glücklich war   \n",
      "61892                        Kannst du ihn mir bestellen?   \n",
      "197584   Die Rückständigkeit jenes Landes ist wohlbekannt   \n",
      "\n",
      "                                                   target  \n",
      "113497        [start] I want to sleep a little more [end]  \n",
      "22466                     [start] It's getting cold [end]  \n",
      "143788    [start] Nobody knew Tom wasn't happy here [end]  \n",
      "61892              [start] Can you order it for me? [end]  \n",
      "197584  [start] The backwardness of that country is we...  \n"
     ]
    }
   ],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "df['source'] = df['German']\n",
    "df['target'] = df['English'].apply(lambda x: '[start] ' + x + ' [end]')\n",
    "df = df.drop(['English', 'German'], axis=1)\n",
    "print(df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ed1df3",
   "metadata": {
    "_cell_guid": "46ceb0db-02a1-429b-914f-c5a94b6b21b8",
    "_uuid": "238dfec9-7bdc-4282-b76f-16a0cac2b6bd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T00:20:24.874623Z",
     "iopub.status.busy": "2025-01-31T00:20:24.874401Z",
     "iopub.status.idle": "2025-01-31T00:20:24.960386Z",
     "shell.execute_reply": "2025-01-31T00:20:24.959435Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.093205,
     "end_time": "2025-01-31T00:20:24.962061",
     "exception": false,
     "start_time": "2025-01-31T00:20:24.868856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# split the data into train, validation, and test sets\n",
    "train_size = int(len(df) * 0.7)\n",
    "val_size = int(len(df) * 0.2)\n",
    "test_size = int(len(df) * 0.1)\n",
    "\n",
    "train_df = df[:train_size]\n",
    "val_df = df[train_size:train_size+val_size]\n",
    "test_df = df[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef4a970",
   "metadata": {
    "_cell_guid": "35058573-a356-4218-80b4-90d20f7ea4d8",
    "_uuid": "21ce0905-7b17-4216-b7e6-3efb229c4605",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T00:20:24.973212Z",
     "iopub.status.busy": "2025-01-31T00:20:24.972916Z",
     "iopub.status.idle": "2025-01-31T00:20:26.792366Z",
     "shell.execute_reply": "2025-01-31T00:20:26.791635Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.826678,
     "end_time": "2025-01-31T00:20:26.794008",
     "exception": false,
     "start_time": "2025-01-31T00:20:24.967330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_tokens = 25000\n",
    "sequence_length = 30\n",
    "\n",
    "# define a custom standardization function that convert to lowercase and strips all punctuations except \"[\" and \"]\" (so we can tell apart \"start\" from \"[start]\").\n",
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    " \n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "# tokenize the data using our custom standardization function\n",
    "source_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1, # add +1 token to our target sentences since they'll be shifted right by 1 during training\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "\n",
    "# index all tokens in the source and target sentences\n",
    "train_source_texts = train_df['source'].values\n",
    "train_target_texts = train_df['target'].values\n",
    "source_vectorization.adapt(train_source_texts)\n",
    "target_vectorization.adapt(train_target_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfee78d",
   "metadata": {
    "_cell_guid": "d61d6dfe-d55f-4f08-b161-495de0dabcc7",
    "_uuid": "20a1d24e-2399-4ec7-9280-1b4488dc6888",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004746,
     "end_time": "2025-01-31T00:20:26.804181",
     "exception": false,
     "start_time": "2025-01-31T00:20:26.799435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Positional Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f7b2b7a",
   "metadata": {
    "_cell_guid": "d74a4ce6-b57e-4e6d-8914-43672bb0c771",
    "_uuid": "e7ad0226-5ebe-4ec5-b624-3b8d785a5c21",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T00:20:26.814877Z",
     "iopub.status.busy": "2025-01-31T00:20:26.814636Z",
     "iopub.status.idle": "2025-01-31T00:20:26.820315Z",
     "shell.execute_reply": "2025-01-31T00:20:26.819636Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012334,
     "end_time": "2025-01-31T00:20:26.821465",
     "exception": false,
     "start_time": "2025-01-31T00:20:26.809131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim) # token embedding layer\n",
    "        self.position_embeddings = keras.layers.Embedding(input_dim=sequence_length, output_dim=output_dim) # position embedding layer\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embedded_tokens = self.token_embeddings(inputs) # embed the tokens\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1) # create the positional information\n",
    "        embedded_positions = self.position_embeddings(positions) # embed the positions \n",
    "        return embedded_tokens + embedded_positions # add the token and position embeddings to create the positional embeddings\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return keras.ops.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9838b346",
   "metadata": {
    "_cell_guid": "0552dc9a-49d8-4bd8-a484-eb53ec2255f3",
    "_uuid": "ad8f89c7-598c-406f-8523-3d9c8adc3bce",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T00:20:26.831969Z",
     "iopub.status.busy": "2025-01-31T00:20:26.831724Z",
     "iopub.status.idle": "2025-01-31T00:20:26.836842Z",
     "shell.execute_reply": "2025-01-31T00:20:26.836237Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011522,
     "end_time": "2025-01-31T00:20:26.837917",
     "exception": false,
     "start_time": "2025-01-31T00:20:26.826395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shape_list(x):\n",
    "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
    "    static = x.shape.as_list()\n",
    "    dynamic = tf.shape(x)\n",
    "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
    "\n",
    "def attention_mask(nd, ns, *, dtype):\n",
    "    \"\"\"1's in the lower triangle, counting from the lower right corner.\n",
    "    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n",
    "    \"\"\"\n",
    "    i = tf.range(nd)[:,None]\n",
    "    j = tf.range(ns)\n",
    "    m = i >= j - ns + nd\n",
    "    return tf.cast(m, dtype)\n",
    "\n",
    "def mask_attn_weights(w):\n",
    "    # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n",
    "    _, _, nd, ns = shape_list(w)\n",
    "    b = attention_mask(nd, ns, dtype=w.dtype)\n",
    "    b = tf.reshape(b, [1, 1, nd, ns])\n",
    "    w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3659e8",
   "metadata": {
    "_cell_guid": "084c54f2-b57b-422c-886a-be79b7a6a452",
    "_uuid": "eb603a9f-d0e8-49f4-b35f-ecb0c64f0448",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004595,
     "end_time": "2025-01-31T00:20:26.847393",
     "exception": false,
     "start_time": "2025-01-31T00:20:26.842798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Scaled-Dot Product Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a636e8ec",
   "metadata": {
    "_cell_guid": "dae8dcc5-53d2-4a7d-b85e-51256d52ee44",
    "_uuid": "efeb57b1-0da4-44e9-aa53-62a9d6ffc939",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T00:20:26.857722Z",
     "iopub.status.busy": "2025-01-31T00:20:26.857531Z",
     "iopub.status.idle": "2025-01-31T00:20:26.861403Z",
     "shell.execute_reply": "2025-01-31T00:20:26.860773Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010353,
     "end_time": "2025-01-31T00:20:26.862531",
     "exception": false,
     "start_time": "2025-01-31T00:20:26.852178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, use_causal_mask=False):\n",
    "    d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scores = tf.matmul(q, k, transpose_b=True) # Matmul of Q and K\n",
    "    scaled_scores = scores / tf.math.sqrt(d_k) # Scale\n",
    "    if use_causal_mask:\n",
    "        scaled_scores = mask_attn_weights(scaled_scores) # Mask (opt.)\n",
    "    weights = tf.nn.softmax(scaled_scores, axis=-1) # SoftMax\n",
    "    output = tf.matmul(weights, v) # Matmul of SoftMax and V\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93221c33",
   "metadata": {
    "_cell_guid": "826c107e-5b7b-4be0-8237-059f2cc3ec8f",
    "_uuid": "f2e2c177-82f2-4eae-9570-9579169bc9d2",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004605,
     "end_time": "2025-01-31T00:20:26.871978",
     "exception": false,
     "start_time": "2025-01-31T00:20:26.867373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Multi-Head Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94942888",
   "metadata": {
    "_cell_guid": "99eea48a-d928-40bc-9337-d9896a1906a4",
    "_uuid": "8c05aef9-cfba-4531-a395-8850c9fe3b42",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T00:20:26.882417Z",
     "iopub.status.busy": "2025-01-31T00:20:26.882222Z",
     "iopub.status.idle": "2025-01-31T00:20:26.889257Z",
     "shell.execute_reply": "2025-01-31T00:20:26.888645Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013676,
     "end_time": "2025-01-31T00:20:26.890458",
     "exception": false,
     "start_time": "2025-01-31T00:20:26.876782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, h, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.h = h\n",
    "        if embed_dim % h != 0:\n",
    "            raise ValueError(\n",
    "                f\"dimension of the embedding space = {embed_dim} should be divisible by number of heads = {h}\"\n",
    "            )\n",
    "        self.q_linear = keras.layers.Dense(embed_dim)\n",
    "        self.k_linear = keras.layers.Dense(embed_dim)\n",
    "        self.v_linear = keras.layers.Dense(embed_dim)\n",
    "        self.concat_linear = keras.layers.Dense(embed_dim)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, shape=(batch_size, -1, self.h, self.embed_dim // self.h))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def concat_heads(self, x, batch_size):\n",
    "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        return tf.reshape(x, (batch_size, -1, self.embed_dim))\n",
    "\n",
    "    def call(self, q, k, v, use_causal_mask=False):\n",
    "        batch_size = tf.shape(k)[0]\n",
    "        q = self.q_linear(q)\n",
    "        k = self.k_linear(k)\n",
    "        v = self.v_linear(v)\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        attention = scaled_dot_product_attention(q, k, v, use_causal_mask)\n",
    "        concat = self.concat_heads(attention, batch_size)\n",
    "        concat = self.concat_linear(concat)\n",
    "        return concat\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MultiHeadAttention, self).get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"h\": self.h,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23305d3",
   "metadata": {
    "_cell_guid": "025dc25e-c12c-4b79-abe8-9b101c0ce223",
    "_uuid": "71419c68-8f35-4cba-9e96-46bafa422d35",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004585,
     "end_time": "2025-01-31T00:20:26.899907",
     "exception": false,
     "start_time": "2025-01-31T00:20:26.895322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d37f6ebd",
   "metadata": {
    "_cell_guid": "a410b648-233f-44e8-8f57-b27fdf3c28b1",
    "_uuid": "bb849731-4c4b-4e0b-8971-9a3888731130",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T00:20:26.910415Z",
     "iopub.status.busy": "2025-01-31T00:20:26.910220Z",
     "iopub.status.idle": "2025-01-31T00:20:26.915139Z",
     "shell.execute_reply": "2025-01-31T00:20:26.914552Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011658,
     "end_time": "2025-01-31T00:20:26.916385",
     "exception": false,
     "start_time": "2025-01-31T00:20:26.904727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.layer_norm_1 = keras.layers.LayerNormalization()\n",
    "        self.layer_norm_2 = keras.layers.LayerNormalization()\n",
    "        self.global_self_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.feed_forward = keras.Sequential(\n",
    "            [keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        \n",
    "    def call(self, x):\n",
    "        # Post layer normalization + residual connections\n",
    "        x = self.layer_norm_1(x + self.global_self_attention(q=x, k=x, v=x))\n",
    "        x = self.layer_norm_2(x + self.feed_forward(x))\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cad964",
   "metadata": {
    "_cell_guid": "21bef62e-9b52-4acb-ae8b-615633356942",
    "_uuid": "bcae3045-a22e-45e7-a0ee-0445cbcd0027",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004709,
     "end_time": "2025-01-31T00:20:26.925930",
     "exception": false,
     "start_time": "2025-01-31T00:20:26.921221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3868a03d",
   "metadata": {
    "_cell_guid": "277828cc-052f-4d9c-912b-9dc26af445e4",
    "_uuid": "5b3f4d7d-34d5-4f49-b612-1ad94bed54c3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T00:20:26.936350Z",
     "iopub.status.busy": "2025-01-31T00:20:26.936133Z",
     "iopub.status.idle": "2025-01-31T00:20:26.941703Z",
     "shell.execute_reply": "2025-01-31T00:20:26.940986Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012074,
     "end_time": "2025-01-31T00:20:26.942814",
     "exception": false,
     "start_time": "2025-01-31T00:20:26.930740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.causal_self_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.cross_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.feed_forward = keras.Sequential(\n",
    "            [keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layer_norm_1 = keras.layers.LayerNormalization()\n",
    "        self.layer_norm_2 = keras.layers.LayerNormalization()\n",
    "        self.layer_norm_3 = keras.layers.LayerNormalization()\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, x, context):\n",
    "        # Post layer normalization + residual connections\n",
    "        x = self.layer_norm_1(x + self.causal_self_attention(q=x, k=x, v=x, use_causal_mask=True))\n",
    "        x = self.layer_norm_2(x + self.cross_attention(q=x, k=context, v=context))\n",
    "        x = self.layer_norm_3(x + self.feed_forward(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b2523",
   "metadata": {
    "_cell_guid": "b151b016-57a3-48aa-9221-1f6e05ed2def",
    "_uuid": "2384a02c-235b-4f68-919a-609f1a6a886c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004626,
     "end_time": "2025-01-31T00:20:26.952316",
     "exception": false,
     "start_time": "2025-01-31T00:20:26.947690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Build and Train Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "153e4fa7",
   "metadata": {
    "_cell_guid": "f9bfe288-e1dc-4735-88da-58ace3da498c",
    "_uuid": "a6773d6b-fa7c-483b-a0e5-438dd9d99095",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T00:20:26.962482Z",
     "iopub.status.busy": "2025-01-31T00:20:26.962264Z",
     "iopub.status.idle": "2025-01-31T00:20:27.365597Z",
     "shell.execute_reply": "2025-01-31T00:20:27.364625Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.410234,
     "end_time": "2025-01-31T00:20:27.367278",
     "exception": false,
     "start_time": "2025-01-31T00:20:26.957044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(source, target):\n",
    "    source_vectors = source_vectorization(source)\n",
    "    target_vectors = target_vectorization(target)\n",
    "    return ({\n",
    "        \"source\": source_vectors, # encoder_inputs\n",
    "        \"target\": target_vectors[:, :-1], # decoder_inputs (truncate by 1 to keep it at the same length as decoder_outputs, which is shifted right by 1).\n",
    "    }, target_vectors[:, 1:]) # decoder_outputs\n",
    "\n",
    "def make_dataset(df):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((df[\"source\"].values, df[\"target\"].values))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "train_ds = make_dataset(train_df)\n",
    "val_ds = make_dataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c1fcefc",
   "metadata": {
    "_cell_guid": "d04e6786-b82c-4c44-9aeb-bad3384c33e9",
    "_uuid": "eea87639-b688-4d9d-abfd-1e3658fe3a2d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T00:20:27.378295Z",
     "iopub.status.busy": "2025-01-31T00:20:27.378035Z",
     "iopub.status.idle": "2025-01-31T00:20:29.448006Z",
     "shell.execute_reply": "2025-01-31T00:20:29.447064Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.076982,
     "end_time": "2025-01-31T00:20:29.449449",
     "exception": false,
     "start_time": "2025-01-31T00:20:27.372467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'transformer_encoder' (of type TransformerEncoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'transformer_decoder' (of type TransformerDecoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 512 # dimension of the embedding space\n",
    "dense_dim = 2048 # dimension of the feed forward network (a rule of thumb is to use 4 times the size of the embeddings)\n",
    "num_heads = 8\n",
    "\n",
    "# the transformer body\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"source\")\n",
    "x = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"target\")\n",
    "x = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "\n",
    "# the transformer head\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "decoder_outputs = keras.layers.Dense(max_tokens, activation=\"softmax\")(x)\n",
    "\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db098082",
   "metadata": {
    "_cell_guid": "60f2854e-5352-4d71-ab9d-0f5f1b8ab3f0",
    "_uuid": "eca2e641-3d65-4577-bbe2-8c9dc3cb5529",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T00:20:29.461407Z",
     "iopub.status.busy": "2025-01-31T00:20:29.461153Z",
     "iopub.status.idle": "2025-01-31T01:04:01.285118Z",
     "shell.execute_reply": "2025-01-31T01:04:01.284216Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2613.38823,
     "end_time": "2025-01-31T01:04:02.843389",
     "exception": false,
     "start_time": "2025-01-31T00:20:29.455159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'multi_head_attention' (of type MultiHeadAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'multi_head_attention_1' (of type MultiHeadAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 59ms/step - accuracy: 0.8047 - loss: 1.3372 - val_accuracy: 0.8763 - val_loss: 0.7533 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 57ms/step - accuracy: 0.8897 - loss: 0.6735 - val_accuracy: 0.9143 - val_loss: 0.4927 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 57ms/step - accuracy: 0.9156 - loss: 0.4779 - val_accuracy: 0.9250 - val_loss: 0.4249 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 57ms/step - accuracy: 0.9268 - loss: 0.3937 - val_accuracy: 0.9278 - val_loss: 0.4038 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 57ms/step - accuracy: 0.9345 - loss: 0.3384 - val_accuracy: 0.9309 - val_loss: 0.3924 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 57ms/step - accuracy: 0.9404 - loss: 0.2973 - val_accuracy: 0.9324 - val_loss: 0.3841 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 57ms/step - accuracy: 0.9455 - loss: 0.2642 - val_accuracy: 0.9344 - val_loss: 0.3791 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 57ms/step - accuracy: 0.9500 - loss: 0.2354 - val_accuracy: 0.9351 - val_loss: 0.3777 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 56ms/step - accuracy: 0.9538 - loss: 0.2121 - val_accuracy: 0.9341 - val_loss: 0.3877 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 56ms/step - accuracy: 0.9573 - loss: 0.1912 - val_accuracy: 0.9366 - val_loss: 0.3838 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 56ms/step - accuracy: 0.9606 - loss: 0.1731 - val_accuracy: 0.9366 - val_loss: 0.3853 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 56ms/step - accuracy: 0.9681 - loss: 0.1351 - val_accuracy: 0.9447 - val_loss: 0.3498 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 57ms/step - accuracy: 0.9752 - loss: 0.1013 - val_accuracy: 0.9452 - val_loss: 0.3473 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 56ms/step - accuracy: 0.9779 - loss: 0.0885 - val_accuracy: 0.9455 - val_loss: 0.3484 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 56ms/step - accuracy: 0.9800 - loss: 0.0799 - val_accuracy: 0.9455 - val_loss: 0.3512 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 56ms/step - accuracy: 0.9813 - loss: 0.0735 - val_accuracy: 0.9455 - val_loss: 0.3533 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 55ms/step - accuracy: 0.9825 - loss: 0.0683 - val_accuracy: 0.9458 - val_loss: 0.3523 - learning_rate: 1.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 56ms/step - accuracy: 0.9829 - loss: 0.0666 - val_accuracy: 0.9458 - val_loss: 0.3522 - learning_rate: 1.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 56ms/step - accuracy: 0.9833 - loss: 0.0654 - val_accuracy: 0.9458 - val_loss: 0.3524 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "EPOCHS = 50\n",
    "checkpoint_filepath = '/tmp/checkpoint.weights.h5'\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=3,\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=6,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "]\n",
    "    \n",
    "transformer.fit(train_ds, \n",
    "                epochs=EPOCHS, \n",
    "                callbacks=callbacks_list,\n",
    "                validation_data=val_ds)\n",
    "\n",
    "transformer.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83148a93",
   "metadata": {
    "_cell_guid": "8191269f-808b-4f9c-a02a-8be3e6486cfa",
    "_uuid": "fdaf321c-846f-4a60-887e-504d77ea53fb",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.297796,
     "end_time": "2025-01-31T01:04:07.501467",
     "exception": false,
     "start_time": "2025-01-31T01:04:05.203671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6e253fb",
   "metadata": {
    "_cell_guid": "9dc50b7e-624b-4f38-b531-82ba9c5b0919",
    "_uuid": "d9490211-01eb-4e4f-8ab2-f4b103467681",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T01:04:12.136997Z",
     "iopub.status.busy": "2025-01-31T01:04:12.136660Z",
     "iopub.status.idle": "2025-01-31T01:04:34.302735Z",
     "shell.execute_reply": "2025-01-31T01:04:34.301862Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 24.514558,
     "end_time": "2025-01-31T01:04:34.304132",
     "exception": false,
     "start_time": "2025-01-31T01:04:09.789574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warst du letzten Sommer in Australien?\n",
      "[start] were you in australia last summer [end]\n",
      "\n",
      "Niemand will, dass ihr das macht\n",
      "[start] nobody wants you to do this [end]\n",
      "\n",
      "Ich zähle auf eure Hilfe\n",
      "[start] i am counting on your help [end]\n",
      "\n",
      "Bitte geh jetzt\n",
      "[start] please leave now [end]\n",
      "\n",
      "Tom hat sich entschieden, eines von seinen Autos an Mary zu verkaufen\n",
      "[start] tom has decided to sell cars to sell mary [end]\n",
      "\n",
      "Wir sind zum Strand gegangen, um zu schwimmen\n",
      "[start] we went to the beach for a swim [end]\n",
      "\n",
      "Tom sagte, dass nicht nur er es hasse, das zu tun\n",
      "[start] tom said he was not only one that [end]\n",
      "\n",
      "Tom und Maria leben in Australien\n",
      "[start] tom and mary live in australia [end]\n",
      "\n",
      "Meinst du, Tom war derjenige, der das getan hat?\n",
      "[start] do you think tom was the one who did that [end]\n",
      "\n",
      "Ich sehe fast jeden Abend fern\n",
      "[start] i watch tv almost every night [end]\n",
      "\n",
      "Ich erinnere mich oft an meine glückliche Kindheit\n",
      "[start] i often remember my childhood happy childhood [end]\n",
      "\n",
      "Tom konnte nicht sprechen\n",
      "[start] tom couldnt speak [end]\n",
      "\n",
      "Er will nicht darin verwickelt werden\n",
      "[start] he doesnt want to be involved in this [end]\n",
      "\n",
      "Ich lächelte und winkte ihnen zu\n",
      "[start] i smiled and waved at you [end]\n",
      "\n",
      "Tom hat mich nach Hause gefahren\n",
      "[start] tom gave me a ride home [end]\n",
      "\n",
      "Ich habe letztens Tom gesehen\n",
      "[start] i saw tom [end]\n",
      "\n",
      "Ich denke, es sieht großartig aus\n",
      "[start] i think it looks great [end]\n",
      "\n",
      "Sie gingen an den Strand\n",
      "[start] they went to the beach [end]\n",
      "\n",
      "Ist Tom gestorben?\n",
      "[start] did tom die [end]\n",
      "\n",
      "Ich werde dich nie verlassen\n",
      "[start] ill never leave you [end]\n",
      "\n",
      "Mach ’ne Fliege!\n",
      "[start] go away [end]\n",
      "\n",
      "Manchmal muss man hart im Nehmen sein\n",
      "[start] sometimes you must take care in it [end]\n",
      "\n",
      "Tōkyō ist größer als jede andere japanische Stadt\n",
      "[start] tokyo is larger than any other japanese city [end]\n",
      "\n",
      "Hebe deine rechte Hand\n",
      "[start] raise your right hand [end]\n",
      "\n",
      "Ich dachte schon, wir müssten sterben!\n",
      "[start] i thought we should die [end]\n",
      "\n",
      "Tom ist von Natur aus Optimist\n",
      "[start] tom is an optimist by nature [end]\n",
      "\n",
      "Ich habe keine Angst davor, kritisiert zu werden\n",
      "[start] im not criticized [end]\n",
      "\n",
      "Schließen Sie die Augen und sagen Sie mir, was Sie hören\n",
      "[start] close your eyes and tell me what they hear [end]\n",
      "\n",
      "Im Wasser ist Blut\n",
      "[start] there is blood in the water [end]\n",
      "\n",
      "Tom nahm das Buch zur Hand und fing an zu lesen\n",
      "[start] tom picked up the book and started reading [end]\n",
      "\n",
      "Ich liebe Tom einfach nicht\n",
      "[start] i just dont love tom [end]\n",
      "\n",
      "Sind Sie jetzt wieder zuhause?\n",
      "[start] are they back home now [end]\n",
      "\n",
      "Ich rechne damit, dass Tom weinen wird\n",
      "[start] i expect tom will cry [end]\n",
      "\n",
      "Tom fährt an diesem Wochenende nicht mit uns zelten\n",
      "[start] tom doesnt go camping with us this weekend [end]\n",
      "\n",
      "Glaubt ihr, dass die Erderwärmung das Ergebnis menschlichen Handelns ist?\n",
      "[start] do you think the global warming is human actions [end]\n",
      "\n",
      "Wir wurden gebeten zu gehen\n",
      "[start] we were asked to leave [end]\n",
      "\n",
      "Tom ging dorthin, wo Maria war\n",
      "[start] tom went there where mary was [end]\n",
      "\n",
      "Ich kann sie nicht als Englischlehrerin ersetzen\n",
      "[start] i cant replace you [end]\n",
      "\n",
      "Sie hätten zu dieser Zeit dort ankommen sollen\n",
      "[start] you shouldve arrived there the time to arrive [end]\n",
      "\n",
      "Was macht dein Vater?\n",
      "[start] what does your father do [end]\n",
      "\n",
      "Ich wünschte, Tom würde sich benehmen\n",
      "[start] i wish tom would behave himself [end]\n",
      "\n",
      "Ich kann nur eine Minute bleiben\n",
      "[start] i can only one minute [end]\n",
      "\n",
      "Tom weiß nicht, ob Mary die Wahrheit sagt oder nicht\n",
      "[start] tom doesnt know whether mary will tell the truth or not [end]\n",
      "\n",
      "Tom lebt auf einer Insel in den Tropen\n",
      "[start] tom lives on an island in the island [end]\n",
      "\n",
      "Ich wette, dass ich eher dort bin als du!\n",
      "[start] i bet that im more than you are [end]\n",
      "\n",
      "Ich soll ihn dort treffen\n",
      "[start] i am supposed to meet him there [end]\n",
      "\n",
      "Tote Hunde beißen nicht\n",
      "[start] dead dogs arent bite [end]\n",
      "\n",
      "Ich hatte nie eine feste Arbeit\n",
      "[start] i never had a steady job [end]\n",
      "\n",
      "Ich sah aus dem Fenster, sah dabei aber nichts Ungewöhnliches\n",
      "[start] i looked out of the window but nothing out of the ordinary [end]\n",
      "\n",
      "Haltet euch warm\n",
      "[start] keep warm [end]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_vocab = target_vectorization.get_vocabulary()\n",
    "target_index_lookup = dict(zip(range(len(target_vocab)), target_vocab))\n",
    "max_decoded_sentence_length = 30\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = target_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "# 50 random sentences translation\n",
    "for i in range(50):\n",
    "    random_index = np.random.randint(0, len(test_df))\n",
    "    input_sentence = test_df[\"source\"].iloc[random_index]\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "893b1440",
   "metadata": {
    "_cell_guid": "cf7de8b1-f92f-48c0-b62b-94a694a31323",
    "_uuid": "97e5cd08-f34c-458d-99be-3bff643fa685",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T01:04:38.987630Z",
     "iopub.status.busy": "2025-01-31T01:04:38.987317Z",
     "iopub.status.idle": "2025-01-31T01:04:39.933052Z",
     "shell.execute_reply": "2025-01-31T01:04:39.932046Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.257391,
     "end_time": "2025-01-31T01:04:39.934355",
     "exception": false,
     "start_time": "2025-01-31T01:04:36.676964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start] im smart [end]\n",
      "[start] shes smart [end]\n",
      "[start] my brother plays the piano [end]\n",
      "[start] he is a waiter [end]\n"
     ]
    }
   ],
   "source": [
    "print(decode_sequence(\"ich bin klug\"))\n",
    "print(decode_sequence(\"sie ist klug\"))\n",
    "print(decode_sequence(\"meine bruder spielt klavier\"))\n",
    "print(decode_sequence(\"er ist kellner \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d15216d",
   "metadata": {
    "_cell_guid": "d36e5470-4628-472e-9306-8b4cb13d7ade",
    "_uuid": "0c563807-116f-42a3-8c71-142efe59a159",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.358874,
     "end_time": "2025-01-31T01:04:44.582369",
     "exception": false,
     "start_time": "2025-01-31T01:04:42.223495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Export**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0675e688",
   "metadata": {
    "_cell_guid": "9da0bb6f-9b4a-49c5-98a2-8cf05dc7bcb9",
    "_uuid": "05888f30-7534-4953-967b-2bcff09ac7d8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-31T01:04:49.237785Z",
     "iopub.status.busy": "2025-01-31T01:04:49.237493Z",
     "iopub.status.idle": "2025-01-31T01:04:50.154552Z",
     "shell.execute_reply": "2025-01-31T01:04:50.153836Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.305937,
     "end_time": "2025-01-31T01:04:50.156178",
     "exception": false,
     "start_time": "2025-01-31T01:04:46.850241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Save the entire model (architecture + weights + optimizer state)\n",
    "transformer.save(\"transformer_de_toen_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6574386,
     "sourceId": 10618490,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2685.584678,
   "end_time": "2025-01-31T01:04:55.327457",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-31T00:20:09.742779",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
